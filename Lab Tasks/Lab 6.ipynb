{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2016331092.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZScXP-SL4Ku"
      },
      "source": [
        "ba4h -> Generate the Convolution of a Spectrum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etI0EQcmZPmF"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EFEM0AtL8Su",
        "outputId": "4ab106f5-6539-4395-e5a7-7014a2151a70"
      },
      "source": [
        "def Convolution(spectrum):\n",
        "  spectrum.sort()\n",
        "  output = []\n",
        "  for i in spectrum:\n",
        "    for j in spectrum:\n",
        "      if i-j > 0:\n",
        "        output.append(i-j)\n",
        "  freq = {}\n",
        "  for item in output:\n",
        "      if item in freq:\n",
        "          freq[item] += 1\n",
        "      else:\n",
        "          freq[item] = 1\n",
        "  sorted_list = [k for k, j in sorted(freq.items(), key=lambda item: item[1], reverse=True)] #sorts by count and returns key\n",
        "  ans = []\n",
        "  for item in sorted_list:\n",
        "      ans += [item] * freq[item]\n",
        "  return ans\n",
        " \n",
        "\n",
        "with open('/content/rosalind_ba4h.txt', 'r') as f:\n",
        "  for line in f:  #Line is a string, split the string on whitespace\n",
        "    numbers_str = line.split()\n",
        "    #convert numbers to int\n",
        "    spec = [int(x) for x in numbers_str] \n",
        "  print(\" \".join(map(str, Convolution(spec))))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 137 186 186 49 323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Jc2ePo0JRU"
      },
      "source": [
        "ba9g -> Construct the Suffix Array of a String\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlnr9bdZsRpE",
        "outputId": "eef4ab69-810c-48a4-b9ae-93440b84c8e7"
      },
      "source": [
        "def SuffixArray(suffix):\n",
        "  length = len(suffix)\n",
        "  suffixdict = {}\n",
        "  for i in range(len(suffix)):\n",
        "    suffixdict[i] = suffix[i:]\n",
        "  return sorted(suffixdict.keys(), key=lambda x:suffixdict[x])  #sorting according to the suffixes\n",
        "\n",
        "with open('/content/rosalind_ba9g.txt', 'r') as f:\n",
        "  text = f.readline().strip()  #strip removes whitespace from starting and ending\n",
        "  print(', '.join(str(x) for x in SuffixArray(text)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15, 14, 0, 1, 12, 6, 4, 2, 8, 13, 3, 7, 9, 10, 11, 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05t3_kaVBEho"
      },
      "source": [
        "ba9a -> Construct a Trie from a Collection of Patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf_DUHXYBEwX",
        "outputId": "e999a061-c160-4a99-bab6-9919cc616d7a"
      },
      "source": [
        "\n",
        "def TrieConstruction(patterns):\n",
        "  adj_list = {}\n",
        "  numCharMap = {}\n",
        "  edges = {}\n",
        "  j = 1\n",
        "  for pattern in patterns:\n",
        "    curr_node = '0'\n",
        "    for idx in pattern:\n",
        "      if curr_node in adj_list:\n",
        "        chlist = [numCharMap[j] for j in adj_list[curr_node]]\n",
        "        nodelist = adj_list[curr_node]\n",
        "        if idx in chlist:\n",
        "          index = chlist.index(idx)\n",
        "          curr_node = nodelist[index]\n",
        "\n",
        "        else:\n",
        "          numCharMap[str(j)] = idx  #for j store char value, eg. ATAGA -> 1:A, 2:T, etc\n",
        "          adj_list[curr_node]+=(str(j))  #edge from current node to j eg. initially 0(root node) to 1\n",
        "          edges[curr_node, str(j)] = idx  #current nod to j we will traverse the idx of string eg. ATAGA-> 0->1:A\n",
        "          curr_node = str(j)\n",
        "          j = j+1\n",
        "\n",
        "      else:\n",
        "        numCharMap[str(j)] = idx  #for j store char value, eg. ATAGA -> 1:A, 2:T, etc\n",
        "        adj_list[curr_node] = str(j)  #edge from current node to j eg. initially 0(root node) to 1\n",
        "        edges[curr_node, str(j)] = idx  #current nod to j we will traverse the idx of string eg. ATAGA-> 0->1:A\n",
        "        curr_node = str(j)\n",
        "        j = j+1\n",
        "  return edges\n",
        "patterns = [\"ATAGA\", \"ATC\", \"GAT\"]\n",
        "ans = TrieConstruction(patterns)\n",
        "for key, val in ans.items():\n",
        "  print(' -> '.join(key)+':'+val)\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 -> 1:A\n",
            "1 -> 2:T\n",
            "2 -> 3:A\n",
            "3 -> 4:G\n",
            "4 -> 5:A\n",
            "2 -> 6:C\n",
            "0 -> 7:G\n",
            "7 -> 8:A\n",
            "8 -> 9:T\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}